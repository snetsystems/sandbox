version: '3.2'
services:
  influxdb:
    image: ch/influxdb:${INFLUXDB_TAG}
    # Full tag list: https://hub.docker.com/r/library/influxdb/tags/
    build:
      context: ./images/influxdb/
      dockerfile: ./Dockerfile
      args:
        INFLUXDB_TAG: ${INFLUXDB_TAG}
    volumes:
      # Mount for influxdb data directory
      - ./influxdb/data:/var/lib/influxdb
      # Mount for influxdb configuration
      - ./influxdb/config/:/etc/influxdb
    ports:
      # The API for InfluxDB is served on port 8086
      - '8086:8086'
      - '8082:8082'
      # UDP Port
      - '8089:8089/udp'
    networks:
      - brg
    restart: always

  kapacitor:
    image: ch/kapacitor:${KAPACITOR_TAG}
    # Full tag list: https://hub.docker.com/r/library/kapacitor/tags/
    build:
      context: ./images/kapacitor/
      dockerfile: ./Dockerfile-gpu
      args:
        KAPACITOR_TAG: ${KAPACITOR_TAG}
    deploy:
      resources:
        # reservations:
        #   devices:
        #     - driver: nvidia
        #       # count: all
        #       device_ids: ['2','3']
        #       capabilities: [gpu]
        reservations:
          devices:
            - capabilities: [gpu]
    environment:
      - NVIDIA_VISIBLE_DEVICES=MIG-9ddf4c52-5275-52a0-8960-df3a71dbff79
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - TF_FORCE_GPU_ALLOW_GROWTH=true
    volumes:
      # Mount for kapacitor data directory
      - ./kapacitor/data/:/var/lib/kapacitor
      # Mount for kapacitor configuration
      - ./kapacitor/config/:/etc/kapacitor
      # Mount for ai module logs
      - ./kapacitor/logs/:/var/log/kapacitor-ai
      # Mount for kapacitor predict UDF socket path
      - ./kapacitor/sock/:/var/run/kapacitor
      # Mount for ch-ai src path
      - ../ch-ai/src/:/opt/cloudhub/ch-ai-src
      # Mount for conda env path
      - /data/jack/miniconda3/envs/cloudhub/:/opt/cloudhub
    # Kapacitor requires network access to Influxdb
    links:
      - influxdb
    ports:
      # The API for Kapacitor is served on port 9092
      # To avoid collision against Kafka port
      #- "9092:9092"
      - '9094:9092'
    depends_on:
      - influxdb
    networks:
      - brg
    restart: always

  logstash:
    image: ch/logstash:${ELK_TAG}
    build:
      context: ./logstash/
      dockerfile: ./Dockerfile
      args:
        ELK_TAG: $ELK_TAG
    volumes:
      - type: bind
        source: ./logstash/config/logstash.yml
        target: /usr/share/logstash/config/logstash.yml
        read_only: true
      - type: bind
        source: ./logstash/pipeline
        target: /usr/share/logstash/pipeline
        read_only: true
      - type: bind
        source: ./logstash/logs
        target: /usr/share/logstash/logs
    ports:
      - "5044:5044"
      - "5000:5000/tcp"
      - "5000:5000/udp"
      - "9600:9600"
    environment:
      LS_JAVA_OPTS: "-Xmx1g -Xms1g"
    depends_on:
      - influxdb
    networks:
      - brg
    restart: always

  etcd:
    # Full tag list: quay.io/coreos/etcd:v3.3.11
    #image: gcr.io/etcd-development/etcd:${ETCD_TAG}
    image: quay.io/coreos/etcd:${ETCD_TAG}
    entrypoint: /usr/local/bin/etcd
    environment:
      - ETCDCTL_API=3
    command:
      - '--name=etcd1'
      - '--data-dir=/var/lib/etcd'
      - '--initial-advertise-peer-urls=http://etcd:2380'
      - '--listen-peer-urls=http://0.0.0.0:2380'
      - '--listen-client-urls=http://0.0.0.0:2379'
      - '--advertise-client-urls=http://etcd:2379'
      - '--initial-cluster-token=etcd-cluster-token'
      - '--initial-cluster=etcd1=http://etcd:2380'
      - '--initial-cluster-state=new'
      - '--max-request-bytes=10485760' # 10 MBytes
      - '--quota-backend-bytes=8589934592' # 8 GBytes
      - '--auto-compaction-retention=24' # 24 hours
      - '--auto-tls'
      - '--peer-auto-tls'
    volumes:
      # Mount for etcd data directory
      - ./etcd/data:/var/lib/etcd
      # Mount for sharing Host domains
      - /etc/hosts:/etc/hosts
    ports:
      # The API for etcd is served on port
      - '2379:2379'
      - '2380:2380'
    networks:
      - brg
    restart: always

  dcgm-exporter:
    image: nvidia/dcgm-exporter:${DCGM_EXPORTER_TAG}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    hostname: ${HOSTNAME}
    ports:
      - "9400:9400"
    cap_add:
      - SYS_ADMIN
    volumes:
      - ./dcgm-exporter/etc/:/etc/dcgm-exporter
    networks:
      - brg
    restart: always

networks:
  brg:
    driver: bridge
    ipam:
      config:
        - subnet: 172.10.0.0/16
          gateway: 172.10.0.1